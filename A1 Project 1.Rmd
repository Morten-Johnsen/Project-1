---
title: "A1 Project 1"
author: "Johnsen & Johnsen"
date: "`r Sys.Date()`"
output: pdf_document
---
```{r, include = F}
knitr::opts_chunk$set(warning = F, fig.height = 4, message = F, dpi = 500)
rm(list = ls())
library(lubridate)
library(latex2exp)
library(circular)
library(tidyverse)
library(reshape)
library(pheatmap)
library(openair)
library(stringr)
library(numDeriv)
library(gridExtra)
library(openair)
library(PowerNormal)
library(sn)
library(gnorm)
library(emg)
library(survival)
library(survminer)


if (Sys.getenv("LOGNAME") == "mortenjohnsen"){
  setwd("/Users/mortenjohnsen/OneDrive - Danmarks Tekniske Universitet/DTU/9. Semester/02418 - Statistical Modelling/Project-1/")
} else {
  setwd("~/Documents/02418 Statistical Modelling/Assignments/Assignment 1/Project-1")
}
source("testDistribution.R")
```

## Projekt 1: Wind Power Forecast

### Descriptive Statistics

#### Read the data tuno.txt into R

```{r}
D <- read.table("tuno.txt", header=TRUE, sep=" ", 
                as.is=TRUE)

D$date <- as.Date("2003-01-01")-1+D$r.day
D$pow.obs.norm <- D$pow.obs/5000
```


#### Make a graphical presentation of data or parts of the data, and present some summary statistics.

Summary statistics:
```{r}
## Dimensions of D (number of rows and columns)
dim(D)
```
The dataset contains 288 observations of the 8 variables: `r names(D)`.

Summary statistics of the 8 variables:
```{r}
## The last rows/observations
#tail(D)
## Selected summary statistics
summary(D)
## Another type of summary of the dataset
#str(D)
```
As can be seen from the table above, the highest observed generated power was 4681.062, and thus our normalization based on a max of 5000 will yield an observed normalized power to be between [0;1[.

Visualization of the three relevant variables:
```{r}
meltD <- D %>%
  dplyr::select(-r.day, -month, -day, -pow.obs) %>%
  melt(id.vars = "date")

ggplot(meltD)+
  geom_histogram(aes(x = value, fill = variable), colour = "white")+
  facet_wrap(~ variable, scales = "free")+
  theme_bw()+
  labs(fill = "", x = "", y = "")+
  theme(legend.position = "bottom", legend.background = element_rect(colour = "black"),
        plot.subtitle = element_text(face = "italic"))+
  ggtitle("Windspeed, Wind Direction and Generated Power"
          ,subtitle = "Generated power has been standardised by dividing with 5000 kW")
```

The heatmap below, shows that the observed power and the wind speed show the strongest correlation in the dataset.
```{r}
D %>%
  dplyr::select(pow.obs.norm, wd30, ws30) %>%
  cor() %>% 
  pheatmap()

#par(mfrow=c(1,2))
#plot(D$date, D$pow.obs, type = 'l', xlab="Date", ylab="Average daily power production [kW]", 
#     main = 'Development in average daily power production over time', cex.main = 0.8, col=1)
#hist(D$pow.obs, xlab="Power production [kW]", main='Distribution of average daily power production', cex.main=0.8)
```

Outlier analysis:
No outliers were found for the wind direction.
```{r}
outlierFUN <- function(data, quantiles){
  v <- quantile(x = data, probs = quantiles)
  IQR <- v[2] - v[1]
  outliers <- ( ( data < (v[1] - 1.5 * IQR) ) | ( data > (v[2] + 1.5 * IQR) ) ) * data
  return (outliers)
}
D$outlierws30 <- outlierFUN(data = D$ws30, quantiles = c(0.25,0.75))
###              ###
par(mfrow=c(1,2))
plot(D$date, D$ws30, type = 'l', xlab="Date", ylab="Wind speeds [m/s]", cex.main = 0.8, col=1,
     main='Development in wind speeds over time')
points(x = D$date ,y = D$outlierws30, type = 'p', pch = 19, col = "red", cex = 0.25, lwd = 5)
text(as.Date(quantile(D$r.day,probs = 0.8), origin = min(D$date)), quantile(D$ws30, probs = 1), "Outliers",  col = "red")
hist(D$ws30, xlab="Wind speeds [m/s]", main='Distribution of wind speeds', cex.main = 0.8)

# par(mfrow=c(1,2))
# plot(D$date, D$wd30, type = 'l', xlab="Date", ylab=expression(paste("Wind direction. N = 0, E = ", pi/2)), col=1,
#      main='Development in wind directions over time', cex.main = 0.8)
# lines(D$date, replicate(length(D$date), 3*pi/2), type='l', col=2) #W
# lines(D$date, replicate(length(D$date), pi), type='l', col=3) #S
# lines(D$date, replicate(length(D$date), pi/2), type='l', col=4) #E
# lines(D$date, replicate(length(D$date), 0), type='l', col=5) #N
# legend('topleft', legend = c('wd30', 'W', 'S', 'E', 'N'), col = 1:5, lty = 1, cex = 0.5)
# #
# hist(D$wd30, xlab=expression(paste('Wind direction. N = 0, E = ', frac(pi,2))),
#      main='Distribution of wind directions', cex.main = 0.8, freq = TRUE) #####hist to show that wind rose is fine
# abline(v = 3*pi/2, col=2)
# abline(v = pi, col=3)
# abline(v = pi/2, col=4)
# abline(v = 0, col=5)
# legend('topleft', legend = c('wd30', 'W', 'S', 'E', 'N'), col = 1:5, lty = 1, cex = 0.5)

```

The distribution of the wind direction can also be examined through a wind rose visualization as to capture the fact that the wind direction have been supplied in radians, and should as such be treated as a circular distribution.
```{r}
D$wd30dg <- D$wd30 * 180/pi
###wind d
intv <- 4
#Dwinter <- D[1:54,] #for testing the season plots above :) D$date[55] = 2003-03-01
#Dsummer <- D[140:230,] #for testing the season plots above :) D$date[140] = 2003-06-01
windRose(D, ws = "ws30", wd = "wd30dg", ws2 = NA, wd2 = NA,
         ws.int = intv, angle = 30, type = "default", bias.corr = TRUE, cols
         = "heat", grid.line = list(value=4, lty=4, col="lightgrey"), width = 1, seg = NULL, auto.text
         = TRUE, breaks = round(max(D$ws30)/intv), offset = 10, normalise = FALSE, max.freq =
           NULL, paddle = FALSE, key.header = "Wind speed at 30 m", key.footer = "(m/s)",
         key.position = "bottom", key = list(height=2), dig.lab = 3, statistic =
           "prop.count", pollutant = NULL, annotate = FALSE, angle.scale =
           45, border = "black", main="Wind directions distribution (at 30 m)",
         cex.main=0.75)
```

Here we see that the main wind direction is West. It is also from this direction we see the highest wind speeds.

### Simple Models

```{r}
source("testDistribution.R")
```


#### Fit different probability density models to wind power, wind speed and wind direction data. You might consider different models e.g. beta, gamma, log normal, and different transformations e.g. (for wind power). It is important that you consider if the distributions/transformations are reasonable for the data that you try to model.

We try out three different approaches: 1) Box-Cox transformation; 2) Transformation based on Eq. 1 in the assignment description; 3) fit distributions directly to the standardized pow.obs.

##### Box-Cox:
```{r, fig.width = 16, fig.height = 6, warning = F}
#Box-Cox transformation of pow.obs.norm
#Examine different transformations and the achieved fit when fitting a normal
#distribution

lambda <- c(0.0, 0.05, 0.10, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4)
pal <- palette.colors(length(lambda))
BoxCoxPlot <- list()
for (i in 1:length(lambda)){
  xData <- 2*log(D$pow.obs.norm^lambda[i]/(1-D$pow.obs.norm)^(1-lambda[i]))
  n <- nlminb(start = c(-1,1)
              , objective = testDistribution
              , x = xData
              , distribution = "normal")
  
  #simData <- rnorm(n = length(D$pow.obs.norm), mean = n$par[1], sd = n$par[2])
  #D$sim <- simData
  D$BoxCox <- xData
  
  BoxCoxPlot[[paste0(lambda[i])]] <- ggplot(D)+
    #geom_histogram(aes(x = sim, y = ..density..)
    #               , colour = "white"
    #               , alpha = 0.5
    #               , fill = "black")+
    geom_histogram(aes(x = BoxCox, y = ..density..)
                   , colour = "white"
                   , alpha = 0.6
                   , fill = pal[[i]])+
    labs(x = "BoxCox(pow.obs.norm)")+
    ggtitle(paste0("BoxCox Transformation of Windpower, ", expression(lambda), " = ", lambda[i]))+
    #geom_text(x = 2, y = 0.23, label = paste0("NLL = ", round(n$objective,2)))+
    geom_text(x = 2, y = 0.2, label = paste0("(mean, sd) = (", round(n$par[1],2), ",", round(n$par[2],2), ")"))+
    stat_function(fun = dnorm, n = length(D$pow.obs.norm), args = list(mean = n$par[1], sd = n$par[2]), alpha = 0.6, colour = "black")
}

grid.arrange(grobs = BoxCoxPlot)
```

From here it can be seen that a box-cox transformation with lambda = 0.25 might be appropriate. It is however not a good approximation as can be seen from the qqplot below.

```{r}
xData <- 2*log(D$pow.obs.norm^0.25/(1-D$pow.obs.norm)^(1-0.25))
qqnorm(xData)
qqline(xData)
```

##### Eq. 1 Transformation
```{r, fig.width=12,fig.height=5}
#Define transformation function
Trans.eq1 <- function(lambda, y){
  y_lambda <- 1/lambda * log(y^lambda/(1-y^lambda))#, lambda > 0
  return(y_lambda)
}

#Optimization function
#Måske er det bedre at lave nogle undersøgelser selv frem for bare at optimere lambda (Overvej til senere).
#se kode fra lecture 4 linje 5-73
lambda_NLL <- function(lambda, pow.obs.norm = D$pow.obs.norm){
  y <- Trans.eq1(lambda, pow.obs.norm)
  NLL <- -as.numeric(shapiro.test(y)$statistic) #shapiro-wilk normality test.
  return(NLL)
}

theta.hat <- nlminb(start=0.5, objective = lambda_NLL) #hov, den var gone før

#round to two decimal points.
lambda <- round(theta.hat$par, 2)
D$transformed.pow.obs.norm <- Trans.eq1(lambda, D$pow.obs.norm)

#Check qqplot:
par(mfrow = c(1,3))
y <- Trans.eq1(lambda, D$pow.obs.norm)
qqnorm(D$pow.obs.norm)
grid()
qqline(D$pow.obs.norm)
qqnorm(y)
grid()
qqline(y)
hist(y, main = "Transformed Pow.obs with lambda = 0.26")
```
**Change of variable**
$$
y = g(x) = \dfrac{1}{\lambda} log\left(\dfrac{x^{\lambda}}{1-x^{\lambda}} \right)
$$
In order to calculate the new likelihood function for the transformed pow.obs, we use change of variable with $\lambda = 0.26$:
$$
y = g(x) = \dfrac{1}{0.26} log\left(\dfrac{x^{0.26}}{1-x^{0.26}} \right)
$$
Now we can calculate the pdf of y as:
$$
f_y(y) = \dfrac{f_x(x)}{\left\vert \frac{dg}{dx} \right\vert}
$$
This finally yields:
$$
f_x(x) = f_y(y) \left\vert \dfrac{dg}{dx} \right\vert = f_y(y) \dfrac{-1}{x(-1+x^\lambda)}
$$
Here, we can either solve our transformation expression $y=g(x)$ for $x=g^{-1}(y)$ and insert this expression, or we can simply supply the normalized pow.obs to the derivative function and our transformed data to the pdf $f_y(y)$. The likelihood of function for the distribution can now be expressed as:
$$
L(y) = \prod_{i=1}^n f_x(x_i) = f_y(y_i) \dfrac{-1}{x_i(-1+x_i^\lambda)} = \prod_{i=1}^n f_y(y_i)\dfrac{-1}{g^{-1}(y_i)(-1+g^{-1}(y_i)^\lambda)}
$$
Calculating the negative log-likelihood we get:
$$
-\mathcal{L}(y) = -\sum_{i=1}^n log\left(f_y(y_i)\dfrac{-1}{g^{-1}(y_i)(-1+g^{-1}(y_i)^\lambda)}\right)= -\sum_{i=1}^n \left( log(f_y(y_i)) + log\left(\dfrac{-1}{g^{-1}(y_i)(-1+g^{-1}(y_i)^\lambda)} \right) \right)
$$

$$
\Longrightarrow -\mathcal{L(y)} = -\sum_{i=1}^n log(f_y(y_i))-\sum_{i=1}^n log \left( \dfrac{-1}{g^{-1}(y_i)(-1+g^{-1}(y_i)^\lambda)} \right)
$$
Where $f_y(y)$ is the normal distribution pdf with mean=$\mu$ and variance=$\sigma^2$). 

From this expression it can be seen that the contribution of the 

We define this log-likelihood in R and get:

```{r}
dgdx <- function(x,lambda){
  return(-1/(x*(x^lambda - 1)))
}

#Density for y is simply the normal distribution:
nll.y <- function(theta, x){
  y <- Trans.eq1(lambda, x)
  return(-sum(log(dnorm(y, mean = theta[1], sd = theta[2])*dgdx(x, lambda))))
}
theta.hat.y <- nlminb(start = c(0,1), objective = nll.y
       , x = D$pow.obs.norm)

#### Alternative start #### : using g^-1(y) instead of x ####
g_inverse <- function(y,lambda){
  return((1/(exp(y*lambda)+1))^(1/lambda) * exp(y))
}

nll.y.alt <- function(theta, y){
  return(-sum(log(dnorm(y, mean = theta[1], sd = theta[2])*dgdx(g_inverse(y,lambda), lambda))))
}

theta.hat.y.alt <- nlminb(start = c(0,1), objective = nll.y.alt
       , y = Trans.eq1(lambda, D$pow.obs.norm))

theta.hat.y$par

#theta.hat.y.alt$par #using the transformed input instead of x
#These yield the same estimates#
#### Alternative end ####

#plot the transformed data alongside the found distribution
ggplot(D)+
  geom_histogram(aes(x = transformed.pow.obs.norm, y = ..density..))+
  stat_function(fun = dnorm, n = dim(D)[1], args = list(mean = theta.hat.y$par[1]
                                                  , sd = theta.hat.y$par[2]))+
  theme_bw()+
  labs(y = "", x = "Normalized and Transformed Power Production")+
  ggtitle("Power Production")
```


##### No Transformation
Fit an exponential, gamma and beta distribution to the observed wind power data.
```{r,warning = F, fig.width=16,fig.height=6}
par.exp <- nlminb(start = 0.2, objective = testDistribution,
                  distribution = "exponential",
                  x = D$pow.obs.norm)

#par.exp$objective

par.beta <- nlminb(start = c(2,5)
                   , objective = testDistribution
                   , distribution = "beta"
                   , x = D$pow.obs.norm
                   , lower = c(0,0.8))
#par.beta$objective

par.gamma <- nlminb(start = c(2,5)
                    ,objective = testDistribution
                    ,distribution = "gamma"
                    ,x = D$pow.obs.norm)
#par.gamma$objective

#Sampling from the found beta distribution
D$simdata <- rbeta(length(D$pow.obs.norm), shape1 = par.beta$par[1]
                   ,shape2 = par.beta$par[2])
sam.plot.pow.beta <- ggplot(D)+
  geom_histogram(aes(x = pow.obs.norm, y =..density.., fill = "Power production"), alpha = 0.8)+
  geom_histogram(aes(x = simdata, y =..density.., fill = "Simulated data based on fitted distribution"), alpha = 0.4)+
  theme_bw()+
  ylim(c(0,5))+
  scale_fill_manual(values = c("red", "black"))+
  scale_colour_manual(values = "black")+
  stat_function(fun = dbeta, n = length(D$pow.obs.norm), args = list(shape1 = par.beta$par[1],shape2 = par.beta$par[2]), aes(colour = "Fitted distribution"))+
  theme(legend.position = "top", legend.text = element_text(colour = "white"), legend.box = "vertical")+
  guides(fill = guide_legend(override.aes = list(fill = c("white","white")))
         ,colour = guide_legend(override.aes = list(colour = "white")))+
  labs(fill = "", colour = "", x = "", y = "")+
  ggtitle("Beta Distribution")

#Sampling from the found exp distribution
D$simdata <- rexp(length(D$pow.obs.norm), rate = par.exp$par)
sam.plot.pow.exp <- ggplot(D)+
  geom_histogram(aes(x = pow.obs.norm, y = ..density.., fill = "Power production"), alpha = 0.8)+
  geom_histogram(aes(x = simdata, y = ..density.., fill = "Simulated data based on fitted distribution")
                 , alpha = 0.4)+
  theme_bw()+
  scale_fill_manual(values = c("red", "black"))+
  scale_colour_manual(values = "black")+
  stat_function(fun = dexp, n = length(D$pow.obs.norm), args = list(rate = par.exp$par), aes(colour = "Fitted distribution"))+
  theme(legend.position = "top", legend.background = element_rect(colour = "black"), legend.box = "vertical")+
  labs(fill = "", colour = "", x = "", y = "")+
  ggtitle("Exponential Distribution")

#Sampling from the found gamma distribution
D$simdata <- rgamma(length(D$pow.obs.norm), shape = par.gamma$par[1], rate = par.gamma$par[2])
sam.plot.pow.gamma <- ggplot(D)+
  geom_histogram(aes(x = pow.obs.norm, y = ..density.., fill = "Power production"), alpha = .8)+
  geom_histogram(aes(x = simdata, y = ..density.., fill = "Simulated data based on fitted distribution")
                 , alpha = 0.4)+
  scale_fill_manual(values = c("red", "black"))+
  scale_colour_manual(values = "black")+
  theme_bw()+
  ylim(c(0,10))+
  stat_function(fun = dgamma, n = length(D$pow.obs.norm), args = list(shape = par.gamma$par[1], rate = par.gamma$par[2]), aes(colour = "Fitted distribution"))+
  theme(legend.position = "top", legend.text = element_text(colour = "white"), legend.box = "vertical")+
  guides(fill = guide_legend(override.aes = list(fill = c("white","white")))
         ,colour = guide_legend(override.aes = list(colour = "white")))+
  ggtitle("Gamma Distribution")+
  labs(fill = "", colour = "", x = "", y = "")

grid.arrange(sam.plot.pow.beta, sam.plot.pow.exp, sam.plot.pow.gamma, ncol = 3)

#Remove simulated data from the data frame
D <- D %>%
  dplyr::select(-simdata)
```

##### Comparing likelihoods
We compare the likelihoods achieved through the different models by calculation of AIC:
```{r}
print(paste("AIC normal transformation: ", 2*theta.hat.y$objective+2*2))
print(paste("AIC beta distribution: ", 2*par.beta$objective+2*2))
print(paste("AIC exponential distribution: ", 2*par.exp$objective+2*1))
print(paste("AIC gamma distributioun: ", 2*par.gamma$objective+2*2))

#felt the need to compare with objectie and pars for just using normal w/o calculating L based on change of variable:
par.norm <- nlminb(start = c(0,1), objective = testDistribution,
                  distribution = "normal",
                  x = D$transformed.pow.obs.norm)
-par.norm$objective + sum(log(-1/(D$pow.obs.norm*(-1+D$pow.obs.norm^0.26))))
-theta.hat.y$objective
par.norm$par;theta.hat.y$par
#### done with the comparison
```
From this comparison we see that the applied transformation and subsequent fitting of a normal distribution is the most appropriate model. The normal model is `r theta.hat.y$objective/par.beta$objective` times more likely than the beta distribution (p. 30).


For wind speed distributions it is common practice to use the weibull distribution.
```{r}
par.ws30 <- nlminb(start = c(1,1), objective = testDistribution
                   , x = D$ws30
                   , distribution = "weibull"
                   , lower = c(0,0))

ggplot(D)+
  geom_histogram(aes(x = ws30, y = ..count../sum(..count..))
                 , colour = "white"
                 , bins = 30)+
  theme_bw()+
  stat_function(fun = dweibull, n = dim(D)[1], args = list(shape = par.ws30$par[1], scale = par.ws30$par[2]))+
  ggtitle("Wind Speed and the Fitted Weibull Distribution")+
  labs(x = "Wind Speed [m/s]", y = "")
```


Wind direction are supplied as radians in the dataset, and thus it is appropriate to fit circular distributions to this variable. Here we examine a circular normal distribution, wrapped cauchy and a von Mises distribution.
```{r, warning = F}
nll.wrappedNormal <- function(p,x){
  nll <- -sum(log(dwrappednormal(x, mu = circular(p[1]), rho = NULL, sd = p[2])))
  return(nll)
}

nll.wrappedCauchy <- function(p,x){
  nll <- -sum(log(dwrappedcauchy(x, mu = circular(p[1]), rho = p[2])))
  return(nll)
}

nll.vonMises <- function(p,x){
  nll <- -sum(dvonmises(x, mu = circular(p[1]), kappa = p[2], log = T))
  return(nll)
}

wrapped.par <- nlminb(start = c(2,1), objective = nll.wrappedNormal, x = D$wd30)
wrapped.cauc.par <- nlminb(start = c(1,1/10000), lower = c(-Inf, 1/10000), upper = c(Inf, 1),
                           objective = nll.wrappedCauchy, x = D$wd30)
wrapped.vonMises <- nlminb(start = c(0,1), objective = nll.vonMises, x = D$wd30, lower = c(-1000, 0))

ggplot(D)+
  theme_bw()+
  #geom_density(aes(x = wd30.centered, y = ..density..), alpha = .8, colour = "white", fill = "red", colour = "white")+
  geom_histogram(aes(x = wd30, y = ..density..), colour = "white", alpha = .8, bins = 20, fill = "orange")+
  scale_x_continuous(breaks = c(0,pi/2,pi,3/2*pi,2*pi)
                     , labels =c("0", "pi/2", "pi", "3/2pi", "2pi"))+
  #stat_function(fun = dnorm, n = dim(D)[1], args = list(mean = par.wd30$par[1], sd = par.wd30$par[2]))+
  stat_function(fun = dwrappednormal, n = dim(D)[1], args = list(mu = wrapped.par$par[1], sd = wrapped.par$par[2]), aes(colour = "Wrapped Normal"))+
  stat_function(fun = dwrappedcauchy, n = dim(D)[1], args = list(mu = wrapped.cauc.par$par[1],rho = wrapped.cauc.par$par[2]), aes(colour = "Wrapped Cauchy"))+
  #stat_function(fun = dwrappedcauchy, n = dim(D)[1], args = list(mu = -1.5748695, rho = 0.2751607), aes(colour = "Wrapped Cauchy2"))+
  stat_function(fun = dvonmises, n = dim(D)[1], args = list(mu = wrapped.vonMises$par[1], kappa = wrapped.vonMises$par[2]), aes(colour = "Von Mises"))+
  labs(x = "Wind Direction", colour = "")+
  scale_colour_manual(values = c("yellow", "red", "black", "blue"))+
  labs(y = "")+
  ggtitle("Wind direction")
```
```{r}
#Calculate AICs
cat("AIC wrapped normal: ", round(2*wrapped.par$objective+2*2,4)
            ,"\nAIC wrapped cauchy: ", round(2*wrapped.cauc.par$objective+2*2,4)
            ,"\nAIC von Mises:      "     , round(2*wrapped.vonMises$objective+2*2,4))
```


#### Conclude on the most appropriate model for each variable, also report parameters including assessment of their uncertainty. For models that does not include a transformation you should also give an assessment of the uncertainty of the expected value in the model.

##### Wind Power Parameter Estimates and CIs
```{r}
alpha <- 0.05
c <- exp(-0.5 * qchisq(1-alpha, df = 1))
#likelihood-based
mle.pow <- theta.hat.y$par

pow.fun <- function(mu, sd, data){
  return( prod( dnorm(x = data, mean = mu, sd = sd, log = F) ) )
}

l.pow.fun <- function(mu, sd, data){
  return( -sum( dnorm(x = data, mean = mu, sd = sd, log = T) ) )
}
nl.pow.funp <- function(p, data){
  return( -sum( dnorm(x = data, mean = p[1], sd = p[2], log = T) ) )
}

#wald
n <- dim(D)[1]
H.pow.mu <- hessian(l.pow.fun, mle.pow[1], sd = mle.pow[2], data = D$transformed.pow.obs.norm)
V.pow.mu <- as.numeric(1/H.pow.mu)
H.pow.sd <- hessian(l.pow.fun, mle.pow[2], mu = mle.pow[1], data = D$transformed.pow.obs.norm)
V.pow.sd <- as.numeric(1/H.pow.sd)
wald.pow.mu <- mle.pow[1] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.pow.mu)
wald.pow.sd <- mle.pow[2] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.pow.sd)

H.pow.mu.m <- hessian(func = nl.pow.funp, x = theta.hat.y$par, data = D$transformed.pow.obs.norm)
sd.pow.mu.m <- sqrt(diag(solve(H.pow.mu.m)))
wald.pow.mu.m <- theta.hat.y$par[1] + c(-1,1) * qnorm(1-alpha/2) * sd.pow.mu.m[1]
wald.pow.sd.m <- theta.hat.y$par[2] + c(-1,1) * qnorm(1-alpha/2) * sd.pow.mu.m[2]

#round( rbind( wald.pow.mu, wald.pow.mu.m, wald.pow.sd, wald.pow.sd.m, theta.hat.y$par ), digits = 3 )

par(mfrow=c(1,2))
mus <- seq(1.9, 3.3, by = 0.01)
pow1 <- sapply(X = mus, FUN = l.pow.fun, data = D$transformed.pow.obs.norm, sd = mle.pow[2])
plot(mus, exp(-(pow1+max(-pow1))), col = 1, type = "l", xlab = expression(paste(mu)),
     main = TeX("Power Production: $\\mu$"))
grid()
lines(range(mus), c*c(1,1), col = 2)
abline(v = wald.pow.mu, lty = "dashed")

sds <- seq(4.3, 5.2, by = 0.01)
pow2 <- sapply(X = sds, FUN = l.pow.fun, data = D$transformed.pow.obs.norm, mu = mle.pow[1])
plot(sds, exp(-(pow2+max(-pow2))), col = 1, type = "l", xlab = expression(paste(sigma)),
     main = TeX("Power Production: $\\sigma$"))
grid()
lines(range(sds), c*c(1,1), col = 2)
abline(v = wald.pow.sd, lty = "dashed")
```

From these figures it is evident that the profile log-likelihood is sufficiently regular for the 95\% of $\mu$ and $\sigma$ to be accurately found by calculating wald confidence intervals. In fact, it seems that the profile likelihood for $\mu$ is **exactly** regular.


Now we calculate parameter uncertainties for the beta-distribution model (This is mostly for fun, as previous calculations have shown the normal distribution model to be superior).

```{r}
## CI ## WIND POWER BETA
par(mfrow=c(1,1))
alpha <- 0.05
c <- exp(-0.5 * qchisq(1-alpha, df = 1))
#likelihood-based
mle.pow <- par.beta$par

pow.fun <- function(shape1, shape2, data){
  return( prod( dbeta(x = data, shape1 = shape1, shape2 = shape2, log = F) ) )
}

l.pow.fun <- function(shape1, shape2, data){
  return( sum( dbeta(x = data, shape1 = shape1, shape2 = shape2, log = T) ) )
}
l.pow.funp.beta <- function(p, data){
  return( -sum( dbeta(x = data, shape1 = p[1], shape2 = p[2], log = T) ) )
}

CIfun.pow <- function(y, first = T){##### T for shape, F for scale
  if(first){
    return( sum( dbeta(x = D$pow.obs.norm, shape1 = mle.pow[1], shape = mle.pow[2], log = T) ) -
      sum( dbeta(x = D$pow.obs.norm, shape1 = y, shape2 = mle.pow[2], log = T) ) - 
      0.5 * qchisq(1-alpha, df = 1) )
  } else {
    return( sum( dbeta(x = D$pow.obs.norm, shape1 = mle.pow[1], shape = mle.pow[2], log = T) ) -
      sum( dbeta(x = D$pow.obs.norm, shape1 = mle.pow[1], shape2 = y, log = T) ) - 
      0.5 * qchisq(1-alpha, df = 1) ) 
  }
}

par(mfrow=c(1,2))
shape1s <- seq(0, 1, by = 0.001)
pow1 <- sapply(X = shape1s, FUN = pow.fun, data = D$pow.obs.norm, shape2 = mle.pow[2])
plot(shape1s, pow1/max(pow1), col = 1, type = "l", xlab = expression(paste(alpha)),
     main = "Parameter value shape1 for beta model of power production")
pf.based.CI.pow1 <- c(uniroot(f = CIfun.pow, interval = c(0, mle.pow[1]), first = T)$root,
            uniroot(f = CIfun.pow, interval = c(mle.pow[1], 1), first = T)$root)
lines(range(shape1s), c*c(1,1), col = 2)

shape2s <- seq(1, 2, by = 0.001)
pow2 <- sapply(X = shape2s, FUN = pow.fun, data = D$pow.obs.norm, shape1 = mle.pow[1])
plot(shape2s, pow2/max(pow2), col = 1, type = "l", xlab = expression(paste(beta)),
     main = "Parameter value shape2 for beta model of power production")
pf.based.CI.pow2 <- c(uniroot(f = CIfun.pow, interval = c(1, mle.pow[2]), first = F)$root,
             uniroot(f = CIfun.pow, interval = c(mle.pow[2], 2), first = F)$root)
lines(range(shape2s), c*c(1,1), col = 2)

#wald
n <- dim(D)[1]
H.pow.shape1 <- hessian(l.pow.fun, mle.pow[1], shape2 = mle.pow[2], data = D$pow.obs.norm)
V.pow.shape1 <- as.numeric(-1/H.pow.shape1)
H.pow.shape2 <- hessian(l.pow.fun, mle.pow[2], shape1 = mle.pow[1], data = D$pow.obs.norm)
V.pow.shape2 <- as.numeric(-1/H.pow.shape2)
wald.pow.shape1 <- mle.pow[1] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.pow.shape1)
wald.pow.shape2 <- mle.pow[2] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.pow.shape2)

#wald m. matrix
H.pow.shapes.hessian.matrix.based <- hessian(func = l.pow.funp.beta, x = par.beta$par, data = D$pow.obs.norm)
sd.pow.shapes.hessian.matrix.based <- sqrt(diag(solve(H.pow.shapes.hessian.matrix.based)))
wald.pow.shape1.hessian.matrix.based <- par.beta$par[1] + c(-1,1) * qnorm(1-alpha/2) * sd.pow.shapes.hessian.matrix.based[1]
wald.pow.shape2.hessian.matrix.based <- par.beta$par[2] + c(-1,1) * qnorm(1-alpha/2) * sd.pow.shapes.hessian.matrix.based[2]
```
Parameters and uncertainties:
```{r}
cat("MLE: (shape1; shape2) = (",round(mle.pow[1],3),"; ",round(mle.pow[2],3),")\n\n\n")

t(round( data.frame( pf.based.CI.pow1
              , wald.pow.shape1
              , wald.pow.shape1.hessian.matrix.based
              , pf.based.CI.pow2
              , wald.pow.shape2
              , wald.pow.shape2.hessian.matrix.based, row.names = c("LOWER [95%]", "UPPER [95%]"))
       , digits = 3 ))
```


##### Wind speed

Model parameters and uncertainties:
```{r}
## CI ## WIND SPEED
par(mfrow=c(1,2))
#likelihood-based
mle.ws30.weib <- par.ws30$par

ws30.fun <- function(shape, scale, data){#####
  prod(dweibull(x = data, shape = shape, scale = scale, log = F)*2)#to not get full zeros
}

l.ws30.fun <- function(shape, scale, data){
  sum(dweibull(x = data, shape = shape, scale = scale, log = T))
}
nl.ws30.funp <- function(p, data){
  return(-sum(dweibull(x = data, shape = p[1], scale = p[2], log = T)))
}

CIfun.ws30 <- function(y, shape = T){##### T for shape, F for scale
  if(shape){
    sum(dweibull(x = D$ws30, shape = mle.ws30.weib[1], scale = mle.ws30.weib[2], log = T)) -
      sum(dweibull(x = D$ws30, shape = y, scale = mle.ws30.weib[2], log = T)) - 
      0.5 * qchisq(1-alpha, df = 1)
  } else {
    sum(dweibull(x = D$ws30, shape = mle.ws30.weib[1], scale = mle.ws30.weib[2], log = T)) -
      sum(dweibull(x = D$ws30, shape = mle.ws30.weib[1], scale = y, log = T)) - 
      0.5 * qchisq(1-alpha, df = 1) 
  }
}
shapes <- seq(1, 3.5, by = 0.01)
ws30.shape <- sapply(X = shapes, FUN = ws30.fun, scale = mle.ws30.weib[2], data = D$ws30)
plot(shapes, ws30.shape/max(ws30.shape), col = 1, type = "l", xlab = "shape, k",
     main = "Parameter value for shape for weibull model of wind speed")
grid()
pf.CI.ws30.shape <- c(uniroot(f = CIfun.ws30, interval = c(1, mle.ws30.weib[1]), shape = T)$root,
                   uniroot(f = CIfun.ws30, interval = c(mle.ws30.weib[1], 3.5), shape = T)$root)
lines(range(shapes), c*c(1,1), col = 2)

scales <- seq(7, 12, by = 0.01)
ws30.scale <- sapply(X = scales, FUN = ws30.fun, shape = mle.ws30.weib[1], data = D$ws30)
plot(scales, ws30.scale/max(ws30.scale), col = 1, type = "l", xlab = expression(paste("scale, ", lambda)),
     main = "Parameter value for scale for weibull model of wind speed")
grid()
pf.CI.ws30.scale <- c(uniroot(f = CIfun.ws30, interval = c(7, mle.ws30.weib[2]), shape = F)$root,
                   uniroot(f = CIfun.ws30, interval = c(mle.ws30.weib[2], 12), shape = F)$root)
lines(range(scales), c*c(1,1), col = 2)

#wald
n <- dim(D)[1]
H.ws30.shape <- hessian(l.ws30.fun, mle.ws30.weib[1], scale = mle.ws30.weib[2], data = D$ws30)
V.ws30.shape <- as.numeric(-1/H.ws30.shape)
H.ws30.scale <- hessian(l.ws30.fun, mle.ws30.weib[2], shape = mle.ws30.weib[1], data = D$ws30)
V.ws30.scale <- as.numeric(-1/H.ws30.scale)
wald.ws30.shape <- mle.ws30.weib[1] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.ws30.shape)
wald.ws30.scale <- mle.ws30.weib[2] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.ws30.scale)

#wald m. matrix
H.ws30.hessian.matrix.based <- hessian(func = nl.ws30.funp, x = par.ws30$par, data = D$ws30)
sd.ws30.hessian.matrix.based <- sqrt(diag(solve(H.ws30.hessian.matrix.based)))
wald.ws30.shape.hessian.matrix.based <- par.ws30$par[1] + c(-1,1) * qnorm(1-alpha/2) * sd.ws30.hessian.matrix.based[1]
wald.ws30.scale.hessian.matrix.based <- par.ws30$par[2] + c(-1,1) * qnorm(1-alpha/2) * sd.ws30.hessian.matrix.based[2]
```
Uncertainty estimates:

```{r}
cat("MLE: (shape; scale) = (",round(mle.ws30.weib[1],3),"; ",round(mle.ws30.weib[2],3),")\n\n\n")

t(round( data.frame(pf.CI.ws30.shape
                    , wald.ws30.shape
                    , wald.ws30.shape.hessian.matrix.based
                    , pf.CI.ws30.scale
                    , wald.ws30.scale
                    , wald.ws30.scale.hessian.matrix.based
                    , row.names = c("LOWER [95%]", "UPPER [95%]"))
       , digits = 3 ))
```



**Reparametrization of the Weibull model:**

```{r}
#function for numerical estimate of the shape parameter based on mean and variance.
k.func <- function(k,mu,var){
  var.est <- mu^2 * (gamma(1+2/k) - gamma(1+1/k)^2)/gamma((k+1)/k)^2
  return((var - var.est)^2)
}

nll.wei <- function(theta, data){
  mu <- theta[1]
  var <- theta[2]
  k <- nlminb(start = 1, objective = k.func, mu = mu, var = var)$par
  nll <- -sum(dweibull(data, shape = k, scale = mu/gamma((k+1)/k), log = T))
  return(nll)
}

par.repar.wei <- nlminb(start = c(1,0.5), objective = nll.wei, data = D$ws30, lower = c(0,0))

################################################################################################### E[x]: CIs (lb and W), and PL
nll.repar.ws30 <- function(p, data){
  k <- p[1]
  theta <- p[2]
  return( -sum(dweibull(x = data, shape = k, scale = theta / gamma(1 + 1/k), log = T)) )
}
repar.E.ws30 <- nlminb(start = c(1,1), objective = nll.repar.ws30, data = D$ws30) #E[x] = par.E.ws30[2] 

repar.ws30.fun <- function(shape, theta, data){#####
  prod(dweibull(x = data, shape = shape, scale = theta / gamma(1 + 1/shape), log = F)*2)#to not get full zeros
}

repar.l.ws30.fun <- function(shape, theta, data){#####
  sum(dweibull(x = data, shape = shape, scale = theta / gamma(1 + 1/shape), log = T))
}
repar.l.ws30.funp <- function(p, data){#####
  return(-sum(dweibull(x = data, shape = p[1], scale = p[2] / gamma(1 + 1/p[1]), log = T)))
}

CIfun.repar.ws30 <- function(y, data, mles){##### T for shape, F for scale
  k <- mles[1]
  theta <- mles[2]
  sum(dweibull(x = data, shape = k, scale = theta / gamma(1 + 1/k), log = T)) -
    sum(dweibull(x = data, shape = k, scale = y / gamma(1 + 1/k), log = T)) - 
    0.5 * qchisq(1-alpha, df = 1) 
}

Es <- seq(8, 10.4, by = 0.001)
ws30.E <- sapply(X = Es, FUN = repar.ws30.fun, shape = repar.E.ws30$par[1], data = D$ws30)
plot(Es, ws30.E/max(ws30.E), col = 1, type = "l", xlab = expression(paste("Expected value E[x] or ", theta)),
     main = "Expected value for weibull model of wind speed")
grid()
pf.CI.ws30.E <- c(uniroot(f = CIfun.repar.ws30, interval = c(min(Es), repar.E.ws30$par[2]), data = D$ws30, mles = repar.E.ws30$par)$root,
               uniroot(f = CIfun.repar.ws30, interval = c(repar.E.ws30$par[2], max(Es)), data = D$ws30, mles = repar.E.ws30$par)$root)
lines(range(Es), c*c(1,1), col = 2)

H.ws30.E <- hessian(repar.l.ws30.fun, repar.E.ws30$par[2], shape = repar.E.ws30$par[1], data = D$ws30)
V.ws30.E <- as.numeric(-1/H.ws30.E)
wald.ws30.E <- repar.E.ws30$par[2] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.ws30.E)

H.ws30.E.hessian.matrix.based <- hessian(func = repar.l.ws30.funp, x = repar.E.ws30$par, data = D$ws30)
sd.ws30.E.hessian.matrix.based <- sqrt(diag(solve(H.ws30.E.hessian.matrix.based)))
wald.ws30.E.hessian.matrix.based <- repar.E.ws30$par[2] + c(-1,1) * qnorm(1-alpha/2) * sd.ws30.E.hessian.matrix.based[2]

#For the variance:
H.ws30.V.hessian.matrix.based <- hessian(func = nll.wei, x = par.repar.wei$par, data = D$ws30)
sd.ws30.V.hessian.matrix.based <- sqrt(diag(solve(H.ws30.V.hessian.matrix.based)))
wald.ws30.E2.hessian.matrix.based <- par.repar.wei$par[1] + c(-1,1) * qnorm(1-alpha/2) * sd.ws30.V.hessian.matrix.based[1]
wald.ws30.V.hessian.matrix.based <- par.repar.wei$par[2] + c(-1,1) * qnorm(1-alpha/2) * sd.ws30.V.hessian.matrix.based[2]
```

Expected value of the distribution and its uncertainty compared to the estimates achieved through reparametrization:
```{r}
#### Testing reparametrization ####
#calculate mean and variance based on current estimates
k <- par.ws30$par[1]
lambda <- par.ws30$par[2]
#E[X]
#Var[X]
cat("Theoretical estimates:"
  ,"\nE[X]=",lambda*gamma(1+1/k)
  ,"\nVar[X]=", lambda^2 * (gamma(1+2/k) - (gamma(1+1/k))^2)
  ,"\n\nMLE estimates from the reparametrization and parameter estimation:"
  ,"\nmean = shape = ", par.repar.wei$par[1]
  ,"\nvariance = scale = ", par.repar.wei$par[2],"\n\n")

round( t(data.frame(pf.CI.ws30.E, wald.ws30.E, wald.ws30.E.hessian.matrix.based, row.names = c("LOWER [95%]", "UPPER [95%]"))), digits = 3)
```

##### Wind direction 

Parameter estimates and uncertainties.

```{r,warning=F, fig.width=16, fig.height=6}
## CI ## WIND DIRECTION
par(mfrow=c(1,2))
#likelihood-based
mle.wd30 <- wrapped.cauc.par$par

wd30.fun <- function(mu, rho, data){#####
  prod(dwrappedcauchy(x = data, mu = mu, rho = rho))
}

l.wd30.fun <- function(mu, rho, data){#####
  sum( log( dwrappedcauchy(x = data, mu = mu, rho = rho) ) )
}
nl.wd30.funp <- function(p, data){#####
  return(-sum( log( dwrappedcauchy(x = data, mu = p[1], rho = p[2]) ) ))
}

CIfun.wd30 <- function(y, mu = T){##### T from mean, F for sigma
  if(mu){
    return( sum( log( dwrappedcauchy(x = D$wd30, mu = mle.wd30[1], rho = mle.wd30[2]) ) ) -
      sum( log( dwrappedcauchy(x = D$wd30, mu = y, rho = mle.wd30[2]) ) ) -
      0.5 * qchisq(1-alpha, df = 1) )
  } else {
    return( sum( log( dwrappedcauchy(x = D$wd30, mu = mle.wd30[1], rho = mle.wd30[2]) ) ) - 
      sum( log( dwrappedcauchy(x = D$wd30, mu = mle.wd30[1], rho = y) ) ) -
      0.5 * qchisq(1-alpha, df = 1) )
  }
}

mus <- seq(-2.5, -1, by = 0.01)
wd30.mu <- sapply(X = mus, FUN = wd30.fun, rho = mle.wd30[2], data = D$wd30)
plot(mus, wd30.mu/max(wd30.mu), col = 1, type = "l", xlab = expression(paste("peak, ", mu)),
     main = "Parameter value for peak for wrapped cauchy model of wind direction")
grid()
pf.CI.wd30.mu <- c(uniroot(f = CIfun.wd30, interval = c(-2.5, mle.wd30[1]), mu = T)$root,
                uniroot(f = CIfun.wd30, interval = c(mle.wd30[1], -1), mu = T)$root)
lines(range(mus), c*c(1,1), col = 2)

rhos <- seq(0, 0.5, by = 0.005)
wd30.rho <- sapply(X = rhos, FUN = wd30.fun, mu = mle.wd30[1], data = D$wd30)
plot(rhos, wd30.rho/max(wd30.rho), col = 1, type = "l", xlab = expression(paste("concentration, ", rho)),
     main = "Parameter value for concentration factor for wrapped cauchy model of wind direction")
grid()
pf.CI.wd30.rho <- c(uniroot(f = CIfun.wd30, interval = c(0, mle.wd30[2]), mu = F)$root,
                   uniroot(f = CIfun.wd30, interval = c(mle.wd30[2], 0.5), mu = F)$root)
lines(range(rhos), c*c(1,1), col = 2)

#wald
n <- dim(D)[1]
H.wd30.mu <- hessian(l.wd30.fun, mle.wd30[1], rho = mle.wd30[2], data = D$wd30)
V.wd30.mu <- as.numeric(-1/H.wd30.mu)
H.wd30.rho <- hessian(l.wd30.fun, mle.wd30[2], mu = mle.wd30[1], data = D$wd30)
V.wd30.rho <- as.numeric(-1/H.wd30.rho)
wald.wd30.mu <- mle.wd30[1] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.wd30.mu)
wald.wd30.rho <- mle.wd30[2] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.wd30.rho)

#wald m. matrix
H.wd30.hessian.matrix.based <- hessian(func = nl.wd30.funp, x = wrapped.cauc.par$par,  data = D$wd30)
sd.wd30.hessian.matrix.based <- sqrt(diag(solve(H.wd30.hessian.matrix.based)))
wald.wd30.mu.hessian.matrix.based <- wrapped.cauc.par$par[1] + c(-1,1) * qnorm(1-alpha/2) * sd.wd30.hessian.matrix.based[1]
wald.wd30.rho.hessian.matrix.based <- wrapped.cauc.par$par[2] + c(-1,1) * qnorm(1-alpha/2) * sd.wd30.hessian.matrix.based[2]
```

```{r}
cat("MLE: (mu; rho) = (",round(mle.wd30[1],3),"; ",round(mle.wd30[2],3),")\n\n\n")

round( t(data.frame( pf.CI.wd30.mu
                   #, wald.wd30.mu
                   , wald.wd30.mu.hessian.matrix.based
                   , pf.CI.wd30.rho
                   #, wald.wd30.rho
                   , wald.wd30.rho.hessian.matrix.based, row.names = c("LOWER [95%]", "UPPER [95%]"))), digits = 3 )
```


The most appropriate distributions and their parameter estimates (plots) and associated uncertainties (values)
```{r, fig.width=16, fig.height=6, warning = F}
textSize=8
par(mfrow=c(1,4))

temp1 <- paste("mu == ", round(theta.hat.y$par[1], 1),"(",round(wald.pow.mu.m,1)[1],",",round(wald.pow.mu.m,1)[2],")") #
temp2 <- paste("sigma^2 == ", round(theta.hat.y$par[2]^2, 1),"(",round(wald.pow.sd.m[1]^2,1),",",round(wald.pow.sd.m[2]^2,1),")") #
temp <- c(temp1, temp2)

ppN <- ggplot(D)+
  geom_histogram(aes(x = transformed.pow.obs.norm, y = ..density..), colour='white', alpha=0.6, bins=30, fill = "red")+
  theme_bw()+
  stat_function(aes(colour = "Normal Distribution"), fun = dnorm, n = dim(D)[1], args = list(mean = theta.hat.y$par[1], sd = theta.hat.y$par[2]))+
  annotate( "text", x = 3.25/5*max(D$transformed.pow.obs.norm), y = c(0.11, 0.1), label = temp, parse = T, size=textSize  ) +
  scale_colour_manual(values = "black")+
  ggtitle("Power Production (Normal Transformed)")+
  labs(x = "Power Production [Transformed domain]")+
  theme(legend.position = "top"
        ,legend.background = element_rect(fill = "white", color = "black"))+
  labs(colour = "")

temp1 <- paste("alpha == ", round(mle.pow[1], 2),"(",round(wald.pow.shape1.hessian.matrix.based,2)[1],",",round(wald.pow.shape1.hessian.matrix.based,2)[2],")") #par.beta$par[1]
temp2 <- paste("beta == ", round(mle.pow[2], 2),"(",round(wald.pow.shape2.hessian.matrix.based,2)[1],",",round(wald.pow.shape2.hessian.matrix.based,2)[2],")") #par.beta$par[2]
temp <- c(temp1, temp2)

ppB <- ggplot(D)+
  geom_histogram(aes(x = pow.obs.norm, y = ..density..), colour='white', alpha=0.6, bins=30, fill = "red")+
  theme_bw()+
  stat_function(aes(colour = "Beta Distribution"), fun = dbeta, n = dim(D)[1], args = list(shape1 = mle.pow[1], shape2 = mle.pow[2]))+
  ylim(c(0,5))+
  annotate( "text", x = 4/5*max(D$pow.obs.norm), y = c(4.5, 4.1), label = temp, parse = T, size=textSize  ) +
  scale_colour_manual(values = "black")+
  ggtitle("Power Production (Normalized)")+
  labs(x = "1/5000 Power production [kW]")+
  theme(legend.position = "top"
        ,legend.background = element_rect(fill = "white", color = "black"))+
  labs(colour = "")

temp1 <- paste("k == ", round(mle.ws30.weib[1],2),"(",round(wald.ws30.shape.hessian.matrix.based,2)[1],",",round(wald.ws30.shape.hessian.matrix.based,2)[2],")")
temp2 <- paste("lambda == ", round(mle.ws30.weib[2],1), "(",round(wald.ws30.scale.hessian.matrix.based,1)[1], ",",round(wald.ws30.scale.hessian.matrix.based,2)[2],")")
temp3 <- paste("E[X] == ", round(par.repar.wei$par[1],1),"(",round(wald.ws30.E.hessian.matrix.based,1)[1],",",round(wald.ws30.E.hessian.matrix.based,1)[2],")")
temp4 <- paste("V[X] == ", round(par.repar.wei$par[2],1),"(",round(wald.ws30.V.hessian.matrix.based,1)[1],",",round(wald.ws30.V.hessian.matrix.based,1)[2],")")
temp <- c(temp1, temp2, temp3, temp4)

ps <- ggplot(D)+
  geom_histogram(aes(x = ws30, y = ..count../sum(..count..)) , colour = "white", alpha=0.6, bins = 30, fill = "black")+
  theme_bw()+
  stat_function(aes(colour = "Weibull Distribution"), fun = dweibull, n = dim(D)[1], args = list(shape = par.ws30$par[1], scale = par.ws30$par[2])) +
  annotate( "text", x = 4/5*max(D$ws30), y = c(0.09, 0.082, 0.074, 0.066), label = temp, parse = T, size=textSize  ) +
  scale_colour_manual(values = "black")+
  ggtitle("Wind Speed")+
  labs(x = "Wind speed [m/s]")+
  theme(legend.position = "top"
        ,legend.background = element_rect(fill = "white", color = "black"))+
  labs(colour = "")

temp1 <- paste("mu ==", round(mle.wd30[1], 2),"(",round(wald.wd30.mu.hessian.matrix.based,2)[1],",",round(wald.wd30.mu.hessian.matrix.based,2)[2],")") #wrapped.cauc.par$par[1]
temp2 <- paste("rho ==", round(mle.wd30[2],2),"(",round(wald.wd30.rho.hessian.matrix.based,2)[1],",",round(wald.wd30.rho.hessian.matrix.based,2)[2],")") #wrapped.cauc.par$par[2]
temp <- c(temp1, temp2)

pd <- ggplot(D)+
  theme_bw()+
  geom_histogram(aes(x = wd30, y = ..density..), colour = "white", alpha = 0.6, bins = 20, fill = "orange")+
  scale_x_continuous(breaks = c(0,pi/2,pi,3/2*pi,2*pi)
                     , labels =c("0", "pi/2", "pi", "3/2pi", "2pi"))+
  stat_function(aes(colour = "Wrapped Cauchy"), fun = dwrappedcauchy, n = dim(D)[1], args = list(mu = wrapped.cauc.par$par[1], rho = 0.36))+
  annotate( "text", x = 1/5*max(D$wd30), y = c(0.35, 0.325), label = c(temp1,temp2), parse = T, size = textSize  ) +
  scale_colour_manual(values = "black")+
  ggtitle("Wind direction")+
  labs(x = "Wind direction [Radians]")+
  theme(legend.position = "top"
        ,legend.background = element_rect(fill = "white", color = "black"))+
  labs(colour = "")

grid.arrange(ppN,ppB,ps,pd,nrow = 1)
```

First are given the 95% likelihood based and Wald CIs of the parameters of the different models for the power, wind speed, and wind direction observations respetively. The maximum likelihood estimates are also given. Below can be seen the expected value along with the uncertainty thereof for the weibull model of the wind speed distribution. The expected value for the model of the power is not given as the data has been transformed. Further, the expected value for the wrapped cauchy model is not explicitly stated below as it is simply the location parameter $\mu$. These values can be found alongside the other parameters values below.

```{r}
#All CIs of parameters (Findes i bedre format længere oppe.)
round( rbind( wald.pow.mu, wald.pow.mu.m, wald.pow.sd, wald.pow.sd.m, theta.hat.y$par ), digits = 3 )#for norm dist of transformed pow obs.
#they replace the beta dist below: CI.pow1 to mle.pow

round( rbind( pf.based.CI.pow1, wald.pow.shape1, pf.based.CI.pow2, wald.pow.shape2, mle.pow,
              pf.CI.ws30.shape, wald.ws30.shape, pf.CI.ws30.scale, wald.ws30.scale, mle.ws30.weib, 
              pf.CI.wd30.mu, wald.wd30.mu, pf.CI.wd30.rho, wald.wd30.rho, mle.wd30 ), digits = 3 )

round( rbind( wald.pow.shape1.hessian.matrix.based, wald.pow.shape2.hessian.matrix.based, wald.ws30.scale.hessian.matrix.based,
              wald.ws30.shape.hessian.matrix.based, wald.wd30.mu.hessian.matrix.based, wald.wd30.rho.hessian.matrix.based ), digits = 3 ) #wald matrix


round( rbind(pf.CI.ws30.E, wald.ws30.E.hessian.matrix.based), digits=3);round( rbind(repar.E.ws30$par[2]), digits=3)
#wald.ws30.E.m #wald matrix
```

##### Expected values and uncertainty

**Beta**

Beta er ikke nødvendigvis relevant, da vi senere vælger at køre med normal-transformationen

```{r}
alpha <- par.beta$par[1]; beta <- par.beta$par[2]
#Beta: E[X] = alpha/(alpha + beta), Var[X] = alpha*beta/((alpha+beta)^2*(alpha+beta+1))
E.pow.obs <- alpha/(alpha + beta)
CI.E.pow.obs <- alpha/(alpha + beta) + c(-1,1) * qnorm(1-alpha/2) * alpha*beta/((alpha+beta)^2*(alpha+beta+1)) * 1/dim(D)[1]
#(CI.E.pow.obs <- mean(D$pow.obs.norm) + c(-1,1) * qnorm(1-alpha/2) * sd(D$pow.obs.norm) / dim(D)[1])
cat("E[X] =", E.pow.obs, " 95% CI: ", CI.E.pow.obs)
```


**Weibull**

```{r}
#Weibull: E[X] = lambda * gamma(1+1/k); Var[X] = lambda^2*(gamma(1+2/k) - (gamma(1+1/k))^2)
#par.ws30$par[2]*gamma(1+1/par.ws30$par[1]) #mean = lambda * Gamma(1 + 1/k); lambda = scale, k = shape
scale <- par.ws30$par[2]; shape <- par.ws30$par[1]
E.ws30 <- scale*gamma(1+1/shape)
V.ws30 <- scale^2*(gamma(1+2/shape) - (gamma(1+1/shape))^2)
CI.E.ws30 <- E.ws30 + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.ws30) / dim(D)[1] #according to Central Limit Theorem
#(CI.E.ws30 <- mean(D$ws30) + c(-1,1) * qnorm(1-alpha/2) * sd(D$ws30) / dim(D)[1])

cat("E[X] =", E.ws30, " 95% CI: ", CI.E.ws30)
```

**Wrapped Cauchy**

```{r}
#Wrapped Cauchy: E[X] = mu, Var[X] = 1 - exp(-gamma)
#relationship between rho and gamma: gamma = -ln(rho)
mu <- wrapped.cauc.par$par[1]; gamma = -log(wrapped.cauc.par$par[2])
E.wd30 <- mu
V.wd30 <- 1 - exp(-gamma) #or 1 - rho
CI.E.wd30 <- E.wd30 + c(-1,1) * qnorm(1-alpha/2) * V.wd30 / dim(D)[1] #according to Central Limit Theorem
#(CI.E.wd30 <- mle.wd30[1] + c(-1,1) * qnorm(1-alpha/2) * sd(D$wd30) / dim(D)[1]) #mean(D$wd30) instead gives another result

cat("E[X] =", E.wd30, " 95% CI: ", CI.E.wd30)
```





}
logle.fun <- function(theta, data_1_2, sigmahat){
9 * log( 1 - pnorm(data_1_2[2], mean = theta, sd = sigmahat) ) +
sum( dnorm(data_1_2, mean = theta, sd = sigmahat, log = TRUE) )
}
mle.a_theo <- mean(y) #see the solutions. Most steps make sense, though very difficult
mle.b_theo <- mean(y) #see the solutions. Easier to understand than a, because Mat 2 is long gone :(
mle.a <- optimize(logla.fun, theta, data = y, sigmahat = sigma, maximum=TRUE)$maximum  #shown for good measure
mle.b <- optimize(loglb.fun, theta, data = mean(y), sigmahat_bar = sigma/sqrt(n), maximum=TRUE)$maximum  #shown for good measure
mle.c <- optimize(loglc.fun, theta, data = median(y), sigmahat = sigma, maximum=TRUE)$maximum
mle.d <- optimize(logld.fun, theta, data = c( min(y), max(y) ), sigmahat = sigma, maximum=TRUE)$maximum
mle.e <- optimize(logle.fun, theta, data = c( y[1], y[2] ), sigmahat = sigma, maximum=TRUE)$maximum
mle.a_theo;mle.a;mle.b_theo;mle.b;mle.c;mle.d;mle.e
#mle.a;mle.b  #the numerical optimization program yields the same results for a and b as the answer derived mathematically.
#b From 2.5: compare Fisher information I, a) and b) theoretically. c), d), and e) numerical optimization program is used.
i.a_theo <- length(y)/sigma^2 #see Maple or the solutions.
i.b_theo <- length(mean(y))/sigma^2  #see Maple or the solutions.
i.a <-
Ha <- hessian(logla.fun, mle.a, data = y, sigmahat = sigma)
Hb <- hessian(loglb.fun, mle.b, data = mean(y), sigmahat = sigma/sqrt(n))
Hc <- hessian(loglc.fun, mle.c, data = median(y), sigmahat = sigma)
Hd <- hessian(logld.fun, mle.d, data = c( min(y), max(y) ), sigmahat = sigma)
He <- hessian(logle.fun, mle.e, data = c( y[1], y[2] ), sigmahat = sigma)
Va <- as.numeric(-1/Ha)
Vb <- as.numeric(-1/Hb)
Vc <- as.numeric(-1/Hc)
Vd <- as.numeric(-1/Hd)
Ve <- as.numeric(-1/He)
i.a_theo;Va;i.b_theo;Vb;Vc;Vd;Ve #notice here that i.a_theo and i.b_theo actually are Fisher information.
#The other five (three) are simply variances. Though, these still tell us
#that the first two scenarios include the most information.
#c Compute and compare the 99% likelihood-based CIs for theta
?dchisq
# a,b,c,d,e using p. 37 eq. (2.6)
alpha <- 0.01
c <- exp(-1/2 * qchisq(1-alpha,df = 1)) #the same c for all of the five likelihood functions
c.n <- exp(-1/2 * qnorm(1-alpha/2)^2) #chisq of 1-alpha at df = 1 is the same as
#standard normal distribution at 1-alpha squared.
lines(theta, replicate(length(theta), c), type = 'l', col = 1)
lines(range(theta), c * c(1,1), type = 'l', col = 1)
legend("topleft", legend = c('la', 'lb', 'lc', 'ld', 'le','lCI'), col = 1:5, lty = 1)
# c.a we will now determine the likelihood-based CIs numerically
fun.a <- function(x){
logla.fun(theta = mle.a, data = y, sigmahat = sigma)-
logla.fun(theta = x, data = y, sigmahat = sigma)-
1/2 * qchisq(1 - alpha, df = 1)
}
fun.b <- function(x){  # c.b
loglb.fun(theta = mle.b, data_mean = mean(y), sigmahat_bar = sigma/sqrt(n))-
loglb.fun(theta = x, data_mean = mean(y), sigmahat_bar = sigma/sqrt(n))-
1/2 * qchisq(1 - alpha, df = 1)
}
fun.c <- function(x){ # c.c
loglc.fun(theta = mle.c, data_med = median(y), sigmahat = sigma)-
loglc.fun(theta = x, data_med = median(y), sigmahat = sigma)-
1/2 * qchisq(1 - alpha, df = 1)
}
fun.d <- function(x){ # c.d
logld.fun(theta = mle.d, data_min_max = c(min(y),max(y)), sigmahat = sigma)-
logld.fun(theta = x, data_min_max = c(min(y),max(y)), sigmahat = sigma)-
1/2 * qchisq(1 - alpha, df = 1)
}
fun.e <- function(x){ # c.e
logle.fun(theta = mle.e, data_1_2 = c(y[1],y[2]), sigmahat = sigma)-
logle.fun(theta = x, data_1_2 = c(y[1],y[2]), sigmahat = sigma)-
1/2 * qchisq(1 - alpha, df = 1)
}
CIa <- c(uniroot(f = fun.a, interval = c(70, mle.a))$root,
uniroot(f = fun.a, interval = c(mle.a, 90))$root)
CIb <- c(uniroot(f = fun.b, interval = c(70, mle.b))$root,
uniroot(f = fun.b, interval = c(mle.b, 90))$root)
CIc <- c(uniroot(f = fun.c, interval = c(70, mle.c))$root,
uniroot(f = fun.c, interval = c(mle.c, 90))$root)
CId <- c(uniroot(f = fun.d, interval = c(70, mle.d))$root,
uniroot(f = fun.d, interval = c(mle.d, 90))$root)
CIe <- c(uniroot(f = fun.e, interval = c(70, mle.e))$root,
uniroot(f = fun.e, interval = c(mle.e, 90))$root)
likelihoodCIs <- rbind(CIa,CIb,CIc,CId,CIe) #These CIs indicate that the five L(theta) can be ranked as such:
#1) L(theta) based on mean and on the entire data set are equally good. They have equal amounts of information,
#as concluded earlier. 3) The L(theta) based on the median is the 3rd, then 4) is the one based on knowing
#the min and max of y. Leaving knowing the two first values as the least useful scenario for determining
#the likelihood of theta.
likelihoodCIs
#d Compute, from p. 47 we have mle+-1.96*se(mle) for a 95% Wald CI.
sqrt( qchisq(1-alpha, df = 1) ) #instead of 1.96, for this is a 99% Wald CI
qnorm(1-alpha/2) #same value as above
WCIa <- mle.a + c(-1,1) * sqrt( qchisq(1-alpha, df = 1) ) * sqrt(Va)
WCIb <- mle.b + c(-1,1) * sqrt( qchisq(1-alpha, df = 1) ) * sqrt(Vb)
WCIc <- mle.c + c(-1,1) * sqrt( qchisq(1-alpha, df = 1) ) * sqrt(Vc)
WCId <- mle.d + c(-1,1) * sqrt( qchisq(1-alpha, df = 1) ) * sqrt(Vd)
WCIe <- mle.e + c(-1,1) * sqrt( qchisq(1-alpha, df = 1) ) * sqrt(Ve)
WaldCIs <- rbind(WCIa,WCIb,WCIc,WCId,WCIe)
likelihoodCIs;WaldCIs #The likelihood-based and the Wald CIs show approx. the same CIs for a) and b)
#For c) and e) the Wald CI underestimates the width of the CI a bit, however,
#for d) it simply seems as though the CI has shifted approx. 0.2 upwards.
---
title: "propsOfLikelihood"
L <- function(sigmasq, x)
sigmahatsq <- var(x)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
plot(sigmasqseq, la)
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data)
sigmahatsq <- var(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data)
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
la <- sapply( X = sigmasq, FUN = L, data = x)
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
la <- sapply(sigmasq, L, data = x)
la <- sapply(sigmasqseq, FUN = L, data = x)
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
sigmasqseq <- seq(0,10,by = 0.01)
la <- sapply(sigmasqseq, FUN = L, data = x)
plot(sigmasqseq, la)
sigmasqseq <- seq(0, 10, by = 0.01)
la <- sapply(sigmasqseq^2, FUN = L, data = x)
plot(sigmasqseq, la)
sigmaseq <- seq(0, 10, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la)
sigmaseq <- seq(0, 10, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq, la)
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
sigmaseq <- seq(0, 10, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la)
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
sigmaseq <- seq(0, 4, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la)
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
sigmaseq <- seq(0, 4, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la, xlab = '$\sigma^2$', ylab = 'likelihood')
plot(sigmaseq^2, la, xlab = expression(\sigma^2), ylab = 'Likelihood')
plot(sigmaseq^2, la, xlab = '\sigma^2', ylab = 'Profile likelihood')
plot(sigmaseq^2, la, xlab = expression(\sigma^2), ylab = 'Profile likelihood')
plot(sigmaseq^2, la, xlab = expression(paste(\sigma^2)), ylab = 'Profile likelihood')
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
sigmaseq <- seq(0, 4, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la, xlab = expression(paste(\sigma^2)), ylab = 'Profile likelihood')
x <- c(0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41)
L <- function(sigmasq, data){
sigmahatsq <- var(data)
n <- length(data)
(sigmasq)^(-n/2)*exp(-n*sigmahatsq/(2*sigmasq)) #vi bruger bare var i stedet for man
}
sigmaseq <- seq(0, 4, by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la, xlab = expression(paste('Likelihood of', sigma^2)), ylab = 'Profile likelihood')
plot(sigmaseq^2, la, xlab = expression(paste(sigma^2)), ylab = 'Profile likelihood')
plot(sigmaseq^2, la, xlab = expression(paste(sigma^2)), ylab = 'Likelihood', main = expression(paste('Profile likelihood of ', sigma^2)))
sigmaseq <- seq(0, sqrt(30), by = 0.01)
la <- sapply(sigmaseq^2, FUN = L, data = x)
plot(sigmaseq^2, la, xlab = expression(paste(sigma^2)), ylab = 'Likelihood', main = expression(paste('Profile likelihood of ', sigma^2)))
E3.23
?binom
?dbinom
pbinom(29, 30, p = (64-3)/64)
dbimom(29, 30, p = (64-3)/64)
dbinom(29, 30, p = (64-3)/64)
pbinom(29, 30, p = (64-3)/64)
dbnom(29, 30, p = (64-3)/64)
pbinom(29, 30, p = (64-3)/64)
dbinom(29, 30, p = (64-3)/64)
pbinom(29, 30, p = (64-3)/64)
dbinom(29, 30, p = (64-3)/64)
k <- seq(0, 29, by = 1)
k
sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
k <- 29
n <- 30
x <- (64-3)/64
y <- 1 - x
k <- seq(0, 29, by = 1)
sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
pbinom(29, 30, p = (64-3)/64)
dbinom(29, 30, p = (64-3)/64)
sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
pbinom(29, 30, p = (64-3)/64)
k <- 29
n <- 30
x <- (64-3)/64
y <- 1 - x
k <- seq(0, 29, by = 1)
sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
pbinom(29, 30, prob = (64-3)/64)
dbinom(29, 30, pron = (64-3)/64)
k <- 29
n <- 30
x <- (64-3)/64
y <- 1 - x
k <- seq(0, 29, by = 1)
sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
pbinom(29, 30, prob = (64-3)/64)
dbinom(29, 30, prob = (64-3)/64)
pbinom(299, 300, prob = p)
k <- 29
n <- 30
x <- (64-3)/64
y <- 1 - x
k <- seq(0, 29, by = 1)
sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
pbinom(29, 30, prob = x)
dbinom(29, 30, prob = y)
pbinom(299, 300, prob = x)
x
k <- 29
n <- 30
x <- (64-3)/64
y <- 1 - x
k <- seq(0, 29, by = 1)
1 - sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) )
1 - pbinom(29, 30, prob = x)
dbinom(29, 30, prob = y)
1 - pbinom(299, 300, prob = x)
k <- seq(0, 29, by = 1)
n1 <- 30
x <- (64-3)/64
y <- 1 - x
1 - sum( factorial(n)/(factorial(k)*factorial(n-k)) * x^k * y^(n-k) ) #from wiki
1 - pbinom(n1-1, n1, prob = x)
#dbinom(29, 30, prob = y)
n2 <- 300
1 - pbinom(n2-1, n2, prob = x)
n_base_pairs*10^6 <- 4 #4 Mega base pairs
#3c
n_base_pairs <- 4 * 10^6 #4 Mega base pairs
n_bp_pr_amino_acids <- 3
n_amino_acids <- n_base_pairs/n_bp_pr_amino_acids
n1_frames <- n_amino_acids/n1 * (1 - pbinom(n1-1, n1, prob = x)) * 2
n1_frames
n1_frames <- n_amino_acids/n1 * (1 - pbinom(n1-1, n1, prob = x)) * 2
n2_frames <- n_amino_acids/n2 * (1 - pbinom(n2-1, n2, prob = x)) * 2
n1_frames;n2_frames
n1_frames <- n_amino_acids / ( n1 * (1 - pbinom(n1-1, n1, prob = x)) ) * 2
n2_frames <- n_amino_acids / ( n2 * (1 - pbinom(n2-1, n2, prob = x)) ) * 2
n1_frames;n2_frames
x^(n1-1)*y^
x^(n1-1)*y
1/64*x^(n1-1)*y
1/64*x^(n1-1)*y*x
n1
x
y
1/64*x^(n2-1)*y
1/64*x^(n1-1)*y
1/64*x^(n2-1)*y
1/64*x^(n1-1)*y*100
1/64*x^(n1-1)*y
rm(list = ls())
library(lubridate)
library(tidyverse)
library(reshape)
library(stringr)
library(pheatmap)
library(numDeriv)
#Retrieve data from the descriptive statistics script
##### TILPAS DEN HER TIL DEN COMPUTER DEER BRUGES
if (Sys.getenv("LOGNAME") == "mortenjohnsen"){
setwd("/Users/mortenjohnsen/OneDrive - Danmarks Tekniske Universitet/DTU/9. Semester/Statistical Modelling/Project-1/")
} else {
setwd("~/Documents/02418 Statistical Modelling/Assignments/Assignment 1/Project-1")
}
source("descriptiveStatistics.R")
testDistribution <- function(p, x, distribution = "Normal", giveDistributions = F){
if (giveDistributions == T){
NLL <- c("normal", "gamma", "beta", "negative binomial")
distribution = "none"
}
if (str_to_lower(distribution) == "normal"){
mu <- p[1]
sigma <- p[2]
NLL <- -sum(dnorm(x, mean = mu, sd = sigma, log = T))
}
if (str_to_lower(distribution) == "gamma"){
shape <- p[1]
rate <- p[2]
NLL <- -sum(dgamma(x, shape = shape, rate = rate, log = T))
}
if (str_to_lower(distribution) == "beta"){
#The beta distribution only ranges from [0;1] and thus it is
#exclusively relevant to the normalized wind power statistic
#and not the fitting of the other two parameters.
shape1 <- p[1]
shape2 <- p[2]
NLL <- -sum(dbeta(x, shape = shape1, shape2 = shape2, log = T))
}
if (str_to_lower(distribution) == "exponential"){
lambda = p
NLL <- -sum(dexp(x, rate = lambda, log = T))
}
if (str_to_lower(distribution) == "weibull"){
shape = p[1]
scale = p[2]
NLL <- -sum(dweibull(x, shape = shape, scale = scale, log = T))
}
if (str_to_lower(distribution) == "negative binomial"){
alpha <- p[1] #target number of succesfull trials
probs <- p[2] #probability of succes in each trial
NLL <- -sum(dnbinom(x = alpha, size = x, prob = probs, log = T))
}
return(NLL)
}
#### WIND POWER ####
#Fitting models to wind power:
par <- nlminb(start = 0.2, objective = testDistribution,
distribution = "exponential",
x = D$pow.obs.norm)
ggplot(D)+
geom_histogram(aes(x = pow.obs.norm, y = ..density..), bins = 20)+
theme_bw()+
stat_function(fun = dexp, n = length(D$pow.obs.norm), args = list(rate = par$par))
#g.pow.obs
#### WIND SPEED ####
par.ws30 <- nlminb(start = c(1,1), objective = testDistribution
, x = D$ws30
, distribution = "weibull"
, lower = c(0,0))
ggplot(D)+
geom_histogram(aes(x = ws30, y = ..count../sum(..count..))
, colour = "white"
, bins = 30)+
theme_bw()+
stat_function(fun = dweibull, n = dim(D)[1], args = list(shape = par.ws30$par[1], scale = par.ws30$par[2]))
#### WIND DIRECTION ####
#centrerer fordelingen omkring 3/2pi
D$wd30.centered <- D$wd30 - pi/2; D$wd30.centered[D$wd30.centered < 0] = D$wd30.centered[D$wd30.centered < 0] + 2*pi
par.wd30 <- nlminb(start = c(4,4),
objective = testDistribution,
x = D$wd30.centered,
distribution = "normal")
ggplot(D)+
theme_bw()+
geom_density(aes(x = wd30.centered, y = ..density..), alpha = .8, colour = "white", fill = "red", colour = "white")+
geom_density(aes(x = wd30, y = ..density..), colour = "white", alpha = .2, fill = "blue")+
scale_x_continuous(breaks = c(0,pi/2,pi,3/2*pi,2*pi)
, labels =c("0", "pi/2", "pi", "3/2pi", "2pi"))+
stat_function(fun = dnorm, n = dim(D)[1], args = list(mean = par.wd30$par[1], sd = par.wd30$par[2]))
## CI ## WIND POWER
par(mfrow=c(1,1))
alpha <- 0.05
c <- exp(-0.5 * qchisq(1-alpha, df = 1))
#likelihood-based
mle.pow.exp <- par$par
pow.fun <- function(lambda, data){
prod(dexp(x = data, rate = lambda, log = F))
}
l.pow.fun <- function(lambda, data){
sum(dexp(x = data, rate = lambda, log = T))
}
CIfun.pow <- function(y){
sum(dexp(x = D$pow.obs.norm, rate = mle.pow.exp, log = T)) -
sum(dexp(x = D$pow.obs.norm, rate = y, log = T)) -
0.5 * qchisq(1-alpha, df = 1)
}
lambdas <- seq(0.2,7, by = 0.1)
pow <- sapply(X = lambdas, FUN = pow.fun, data = D$pow.obs.norm)
plot(lambdas, pow/max(pow), col = 1, type = "l", xlab = expression(paste(lambda)),
main = "Parameter values for exponential model of power production")
CI.pow <- c(uniroot(f = CIfun.pow, interval = c(0.2, mle.pow.exp))$root,
uniroot(f = CIfun.pow, interval = c(mle.pow.exp, 7))$root)
lines(range(lambdas), c*c(1,1), col = 2)
#wald
H.pow <- hessian(l.pow.fun, mle.pow.exp, data = D$pow.obs.norm)
V.pow <- as.numeric(-1/H.pow)
wald.pow <- mle.pow.exp + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.pow)
## CI ## WIND SPEED
par(mfrow=c(1,2))
#likelihood-based
mle.ws30.weib <- par.ws30$par
ws30.fun <- function(shape, scale, data){#####
prod(dweibull(x = data, shape = shape, scale = scale, log = F)*2)#to not get full zeros
}
l.ws30.fun <- function(shape, scale, data){#####
sum(dweibull(x = data, shape = shape, scale = scale, log = T))
}
CIfun.ws30 <- function(y, shape = T){##### T for shape, F for scale
if(shape){
sum(dweibull(x = D$ws30, shape = mle.ws30.weib[1], scale = mle.ws30.weib[2], log = T)) -
sum(dweibull(x = D$ws30, shape = y, scale = mle.ws30.weib[2], log = T)) -
0.5 * qchisq(1-alpha, df = 1)
} else {
sum(dweibull(x = D$ws30, shape = mle.ws30.weib[1], scale = mle.ws30.weib[2], log = T)) -
sum(dweibull(x = D$ws30, shape = mle.ws30.weib[1], scale = y, log = T)) -
0.5 * qchisq(1-alpha, df = 1)
}
}
shapes <- seq(1, 3.5, by = 0.1)
ws30.shape <- sapply(X = shapes, FUN = ws30.fun, scale = mle.ws30.weib[2], data = D$ws30)
plot(shapes, ws30.shape/max(ws30.shape), col = 1, type = "l", xlab = "shape",
main = "Parameter value for shape for weibull model of wind speed")
CI.ws30.shape <- c(uniroot(f = CIfun.ws30, interval = c(1, mle.ws30.weib[1]), shape = T)$root,
uniroot(f = CIfun.ws30, interval = c(mle.ws30.weib[1], 3.5), shape = T)$root)
lines(range(shapes), c*c(1,1), col = 2)
scales <- seq(7, 12, by = 0.1)
ws30.scale <- sapply(X = scales, FUN = ws30.fun, shape = mle.ws30.weib[1], data = D$ws30)
plot(scales, ws30.scale/max(ws30.scale), col = 1, type = "l", xlab = "scale",
main = "Parameter value for scale for weibull model of wind speed")
CI.ws30.scale <- c(uniroot(f = CIfun.ws30, interval = c(7, mle.ws30.weib[2]), shape = F)$root,
uniroot(f = CIfun.ws30, interval = c(mle.ws30.weib[2], 12), shape = F)$root)
lines(range(scales), c*c(1,1), col = 2)
#wald
n <- dim(D)[1]
H.ws30.shape <- hessian(l.ws30.fun, mle.ws30.weib[1], scale = mle.ws30.weib[2], data = D$ws30)
V.ws30.shape <- as.numeric(-1/H.ws30.shape)
H.ws30.scale <- hessian(l.ws30.fun, mle.ws30.weib[2], shape = mle.ws30.weib[1], data = D$ws30)
V.ws30.scale <- as.numeric(-1/H.ws30.scale)
wald.ws30.shape <- mle.ws30.weib[1] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.ws30.shape)
wald.ws30.scale <- mle.ws30.weib[2] + c(-1,1) * qnorm(1-alpha/2) * sqrt(V.ws30.scale)
## CI ## WIND DIRECTION
par(mfrow=c(1,2))
#likelihood-based
mle.wd30.norm <- par.wd30$par
wd30.fun <- function(mu, sigma, data){#####
prod(dnorm(x = data, mean = mu, sd = sigma, log = F))
}
l.wd30.fun <- function(mu, sigma, data){#####
sum(dnorm(x = data, mean = mu, sd = sigma, log = T))
}
CIfun.wd30 <- function(y, mu = T){##### T from mean, F for sigma
if(mu){
sum(dnorm(x = D$wd30.centered, mean = mle.wd30.norm[1], sd = mle.wd30.norm[2], log = T)) -
sum(dnorm(x = D$wd30.centered, mean = y, sd = mle.wd30.norm[2], log = T)) -
0.5 * qchisq(1-alpha, df = 1)
} else {
sum(dnorm(x = D$wd30.centered, mean = mle.wd30.norm[1], sd = mle.wd30.norm[2], log = T)) -
sum(dnorm(x = D$wd30.centered, mean = mle.wd30.norm[1], sd = y, log = T)) -
0.5 * qchisq(1-alpha, df = 1)
}
}
mus <- seq(0, 6, by = 0.1)
wd30.mu <- sapply(X = mus, FUN = wd30.fun, sigma = mle.wd30.norm[2], data = D$wd30.centered)
plot(mus, wd30.mu/max(wd30.mu), col = 1, type = "l", xlab = expression(paste(mu)),
main = "Parameter value for mean for normal model of wind direction")
CI.wd30.mu <- c(uniroot(f = CIfun.wd30, interval = c(0, mle.wd30.norm[1]), mu = T)$root,
uniroot(f = CIfun.wd30, interval = c(mle.wd30.norm[1], 6), mu = T)$root)
lines(range(mus), c*c(1,1), col = 2)
sigmas <- seq(0, 2.5, by = 0.1)
wd30.sigma <- sapply(X = sigmas, FUN = wd30.fun, mu = mle.wd30.norm[1], data = D$wd30.centered)
plot(sigmas^2, wd30.sigma/max(wd30.sigma), col = 1, type = "l", xlab = expression(paste(sigma^2)),
main = "Parameter value for var for normal model of wind direction")
CI.wd30.sigma <- c(uniroot(f = CIfun.wd30, interval = c(0, mle.wd30.norm[2]), mu = F)$root,
uniroot(f = CIfun.wd30, interval = c(mle.wd30.norm[2], 2.5), mu = F)$root)
CI.wd30.sigmasq <- CI.wd30.sigma^2
lines(range(sigmas^2), c*c(1,1), col = 2)
#wald
n <- dim(D)[1]
H.wd30.mu <- hessian(l.wd30.fun, mle.wd30.norm[1], sigma = mle.wd30.norm[2], data = D$wd30.centered)
V.wd30.mu <- as.numeric(-1/H.wd30.mu)
H.wd30.sigma <- hessian(l.wd30.fun, mle.wd30.norm[2], mu = mle.wd30.norm[1], data = D$wd30.centered)
V.wd30.sigma <- as.numeric(-1/H.wd30.sigma)
I11 <- n/mle.wd30.norm[2]^2;1/I11;V.wd30.mu# P. 59
I22 <- n/( 2 * mle.wd30.norm[2]^4 );1/I22;V.wd30.sigma#Det driller med denne :(
wald.wd30.mu <- mle.wd30.norm[1] + c(-1,1) * qnorm(1-alpha/2) * sqrt(1/I11)
wald.wd30.sigmasq <- mle.wd30.norm[2]^2 + c(-1,1) * qnorm(1-alpha/2) * sqrt(1/I22)
#All CIs of parameters
round(rbind(CI.pow, wald.pow, mle.pow.exp, CI.ws30.shape, wald.ws30.shape,
CI.ws30.scale, wald.ws30.scale,mle.ws30.weib, CI.wd30.mu, wald.wd30.mu,
CI.wd30.sigmasq, wald.wd30.sigmasq, c(mle.wd30.norm[1], mle.wd30.norm[2]^2)), digits=5)
#All CIs of parameters
mle.wd30.norm.sigmasq <- c(mle.wd30.norm[1], mle.wd30.norm[2]^2)
round(rbind(CI.pow, wald.pow, mle.pow.exp, CI.ws30.shape, wald.ws30.shape,
CI.ws30.scale, wald.ws30.scale,mle.ws30.weib, CI.wd30.mu, wald.wd30.mu,
CI.wd30.sigmasq, wald.wd30.sigmasq, mle.wd30.norm.sigmasq), digits=5)
#All CIs of parameters
mle.wd30.norm.sq <- c(mle.wd30.norm[1], mle.wd30.norm[2]^2)
round(rbind(CI.pow, wald.pow, mle.pow.exp, CI.ws30.shape, wald.ws30.shape,
CI.ws30.scale, wald.ws30.scale,mle.ws30.weib, CI.wd30.mu, wald.wd30.mu,
CI.wd30.sigmasq, wald.wd30.sigmasq, mle.wd30.norm.sq), digits=5)
